{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2OX2qe2JxJy"
      },
      "source": [
        "## Programming Assignment 4\n",
        "This week you will implement a Naive Bayes classifier.\n",
        "The assignment can be found on Canvas. Please only edit parts of the code that are marked by a TODO. \n",
        "\n",
        "In the first cell, we download the data.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xflyoRy15WKl"
      },
      "source": [
        "!wget -O files.zip https://github.com/probabll/basic-probability-programming/raw/master/weekly_tasks/week4/homework/files_for_development.zip\n",
        "!unzip files.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptMxd9IXKQQ7"
      },
      "source": [
        "```accuracy_checker``` \n",
        "checks the overlap between the golden list and the predictions made by the classifier. Note you don't need to edit this file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_TDC7sFPYw"
      },
      "source": [
        "'''\n",
        "Created on Sep 30, 2015\n",
        "\n",
        "@author: Philip Schulz\n",
        "'''\n",
        "\n",
        "import sys\n",
        "\n",
        "def accuracy_checker(gold, pred):\n",
        "    \n",
        "    gold_labels = dict()\n",
        "    pred_labels = dict()\n",
        "\n",
        "    try:\n",
        "        with open(gold) as goldFile:\n",
        "            for line in goldFile:\n",
        "                elements = line.split()\n",
        "                gold_labels[elements[0]] = elements[1]\n",
        "                \n",
        "        with open(pred) as pred_file:\n",
        "            for line in pred_file:\n",
        "                elements = line.split()\n",
        "                pred_labels[elements[0]] = elements[1]\n",
        "    \n",
        "    except IOError as e:\n",
        "        print(e)\n",
        "        print(\"One of the files does not exist on your computer.\")\n",
        "        sys.exit(0)\n",
        "        \n",
        "    if len(gold_labels) != len(pred_labels):\n",
        "        print ('The lists are of different size. Please make sure to only ' +\n",
        "        'use equally sized lists.')\n",
        "        sys.exit(0)\n",
        "        \n",
        "    overlap = 0\n",
        "    for doc, label in gold_labels.items():\n",
        "        if pred_labels[doc] == label:\n",
        "            overlap += 1\n",
        "    \n",
        "    overlap /= float(len(gold_labels))\n",
        "    overlap *= 100\n",
        "    \n",
        "    print('The overlap between the gold list and the student output is {}%'.format(overlap))\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "    # main(sys.argv[1:])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5td6ZhrHK2l0"
      },
      "source": [
        "The following cell implements the methods of the class ```NaiveBayes```. Please edit the parts which are marked by a TODO. See the assignment for more details. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5RL13dB_l2R"
      },
      "source": [
        "\"\"\"\n",
        "The file implementing Naive Bayes classifier.\n",
        "\"\"\"\n",
        "###\n",
        "# You have to work on this file. Your task is to implement the methods\n",
        "# marked as TODO.\n",
        "\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "class NaiveBayes(object):\n",
        "    '''\n",
        "    This class implements a naive bayes classifier.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self):\n",
        "        '''\n",
        "        Constructor\n",
        "        '''\n",
        "        # The following Counter will be used to count the number of text\n",
        "        # occurrencies per label.\n",
        "        self.label_counts = Counter()\n",
        "        # The following dictionary will be used to map labels to Counters. Each of these Counters\n",
        "        # contains the feature counts given the label.\n",
        "        self.feature_counts = dict()\n",
        "\n",
        "        # The following dictionary will be used to collect\n",
        "        # prior probabilities of labels.\n",
        "        self.label_probs = dict()\n",
        "        # The following dictionary will be used to collect feature\n",
        "        # probabilities given a label.\n",
        "        self.feature_probs = dict()\n",
        "        #A set that contains all words encountered during training.\n",
        "        self.vocabulary = set()\n",
        "\n",
        "    def train(self, data, label):\n",
        "        '''\n",
        "        Train the classifier by counting features in the data set.\n",
        "        \n",
        "        :param data: A stream of string data from which to extract features\n",
        "        :param label: The label of the data\n",
        "        '''\n",
        "        for line in data:\n",
        "            self.add_feature_counts(line.split(), label)\n",
        "    \n",
        "    def add_feature_counts(self, features, label):\n",
        "        '''\n",
        "        Count the features in a feature list.\n",
        "        \n",
        "        :param features: a list of features.\n",
        "        :param label: the label of the data file from which the features were extracted.\n",
        "        '''\n",
        "        # This method updates feature_counts by features given the label. It\n",
        "        # should also update vocabulary with features.\n",
        "        # TODO: implement this!\n",
        "        pass\n",
        "\n",
        "    def smooth_feature_counts(self, smoothing=1):\n",
        "        '''Smooth the collected feature counts\n",
        "\n",
        "        :param smoothing: The smoothing constant\n",
        "        '''\n",
        "        # This method smoothes counts in feature_counts. Check the assignment\n",
        "        # description on how to do this.\n",
        "        # TODO: implement this!\n",
        "        pass\n",
        "        \n",
        "    def update_label_count(self,label):\n",
        "        '''\n",
        "        Increase the count for the supplied label by 1.\n",
        "        \n",
        "        :param label: The label whose count is to be increased.\n",
        "        '''\n",
        "        self.label_counts.update([label])\n",
        "        \n",
        "    def log_normalise_label_probs(self):\n",
        "        '''\n",
        "        Take label counts in label_counts, normalize them to\n",
        "        probabilities, transform them to logprobs and update label_probs\n",
        "        with the logprobs.\n",
        "        '''\n",
        "        # Take label_counts, and update label_probs.\n",
        "        # label_probs should have labels as keys. The values are\n",
        "        # log-probability of each label. The probability is created\n",
        "        # by normalizing values in label_counts, after that it is\n",
        "        # log-transformed.\n",
        "        # TODO: Implement this!\n",
        "        pass\n",
        "            \n",
        "    def log_normalise_feature_probs(self):\n",
        "        '''\n",
        "        Take feature counts in feature_counts and for each label, normalize\n",
        "        them to probabilities and turn them into logprobs. update\n",
        "        feature_probs with the created logprobs.\n",
        "        '''\n",
        "        # Take feature_counts, update feature_probs.\n",
        "        # feature_probs have labels as keys. The values are\n",
        "        # dictionaries that have features as keys as log-probs as values.\n",
        "        # TODO: Implement this!\n",
        "        pass\n",
        "                \n",
        "    def predict(self, data):\n",
        "        ''' \n",
        "        Predict the most probable label according to the model on a stream of data.\n",
        "        \n",
        "        :param data: A stream of string data from which to extract features\n",
        "        :return: the most probable label for the data (type string)\n",
        "        '''\n",
        "        # TODO: implement this!\n",
        "        pass \n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3t4kYX_LCu2"
      },
      "source": [
        "The following piece of code trains the classifier, saves the predictions to ```predictions.txt``` and evaluates against the golden list. You can run the code by executing this cell. You don't need to edit this cell. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vIOF-BG_dwz"
      },
      "source": [
        "'''\n",
        "Created on Sep 23, 2015\n",
        "\n",
        "@author: Philip Schulz\n",
        "@modifications: Jakub Dotlacil, April 26, 2018\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "# TODO: replace <package> by the name of the package that you store these files in\n",
        "# from naive_bayes import NaiveBayes\n",
        "from os import listdir, remove, system\n",
        "from os.path import isfile, join\n",
        "\n",
        "# TODO: Please write the command that you use to call Python in the terminal here\n",
        "# (most likely, the command is python or python3)\n",
        "my_python = \"\"\n",
        "\n",
        "def train_model(corpus_dir, classifier):\n",
        "    '''Train a classifier on a training corpus where labels are provided.\n",
        "\n",
        "    :param corpus_dir: The path to the training folder\n",
        "    :param classifier: The classifier to be trained\n",
        "    '''\n",
        "    print('Starting training at {}'.format(datetime.now()))\n",
        "\n",
        "    for directory in listdir(corpus_dir):\n",
        "        print(\"Training on label {}\".format(directory))\n",
        "        directory_path = join(corpus_dir, directory)\n",
        "        for text_file in listdir(directory_path):\n",
        "            file_path = join(directory_path, text_file)\n",
        "            classifier.update_label_count(directory)\n",
        "            try:\n",
        "                with open(file_path) as data_file:\n",
        "                    classifier.train(data_file, directory)\n",
        "            except IOError as e:\n",
        "                print(e)\n",
        "                print(\"It seems that the text_file {} is damaged.\".format(text_file))\n",
        "                sys.exit(0)\n",
        "\n",
        "    print(\"Starting to smooth and normalise at {}\".format(datetime.now()))\n",
        "    classifier.smooth_feature_counts()\n",
        "    classifier.log_normalise_label_probs()\n",
        "    classifier.log_normalise_feature_probs()\n",
        "\n",
        "    print(\"Finished training at {}\".format(datetime.now()))\n",
        "\n",
        "def make_predictions(predictions_file, test_dir, classifier):\n",
        "    '''Make predictions on data with missing label\n",
        "\n",
        "    :param predictions_file: The file to which the ouput predictions should be written\n",
        "    :param test_dir: The path to the directory containing the test items\n",
        "    :param classifier: A trained classifier\n",
        "    '''\n",
        "    print(\"Start making predictions at {}\".format(datetime.now()))\n",
        "    \n",
        "    if isfile(predictions_file):\n",
        "        remove(predictions_file)\n",
        "    \n",
        "    for test_file in listdir(test_dir):\n",
        "        try:\n",
        "            with open(join(test_dir, test_file)) as test, open(predictions_file, \"a\") as out:\n",
        "                prediction = classifier.predict(test)\n",
        "                out.write(test_file + \"\\t{}\\n\".format(prediction))\n",
        "        except IOError as e:\n",
        "            print(e)\n",
        "            print(\"Something went wrong while reading test file {}\".format(test_file))\n",
        "            sys.exit(0)\n",
        "            \n",
        "    print(\"Finished making predictions at {}\".format(datetime.now()))\n",
        "\n",
        "def main():\n",
        "    '''Standard method in Python that does not need a docstring. Don't worry about it for now, we will get to know it\n",
        "    more deeply in week 6.\n",
        "    '''\n",
        "    \n",
        "    corpus_dir = 'files_for_development/20news-18828'\n",
        "    test_dir = 'files_for_development/dev-set'\n",
        "    keys_file = 'files_for_development/dev_keys.txt'\n",
        "\n",
        "    nb_classifier = NaiveBayes()\n",
        "\n",
        "    if corpus_dir:\n",
        "        train_model(corpus_dir, nb_classifier)\n",
        "\n",
        "    if test_dir:\n",
        "        make_predictions(\"predictions.txt\", test_dir, nb_classifier)\n",
        "\n",
        "    if keys_file:\n",
        "        accuracy_checker(keys_file, \"predictions.txt\")\n",
        "        # system(\"{} accuracy_checker.py {} predictions.txt\".format(my_python, keys_file))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7m86EIjMgKD"
      },
      "source": [
        "We can run the accuracy check separately from the training process as following:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSKt6G7CHc3o"
      },
      "source": [
        "accuracy_checker('predictions.txt', 'files_for_development/dev_keys.txt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}